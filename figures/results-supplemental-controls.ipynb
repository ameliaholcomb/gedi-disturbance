{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pylr2 import regress2\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import spark_postgis\n",
    "from src import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = spark_postgis.get_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_all = spark.read.parquet((constants.RESULTS_PATH / \"gedi_neighbors_nau_l24a\").as_posix())\n",
    "sdf_all.createOrReplaceTempView(\"shots_table\")\n",
    "sdf_all = spark.sql(\"SELECT *, ST_GeomFromWKB(t1_geometry) AS t1_geom, ST_GeomFromWKB(t2_geometry) AS t2_geom FROM shots_table\")\n",
    "sdf_all = sdf_all.drop(\"t1_geometry\", \"t2_geometry\")\n",
    "print(sdf_all.count())\n",
    "sdf_all.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_intact_s1 = spark.read.parquet((constants.RESULTS_PATH / \"intact_control_s1\").as_posix())\n",
    "sdf_intact_s2 = spark.read.parquet((constants.RESULTS_PATH / \"intact_control_s2\").as_posix())\n",
    "sdf_intact = sdf_intact_s1.select([\"t1_shot_number\", \"t2_shot_number\"]).join(sdf_intact_s2, on=[\"t1_shot_number\", \"t2_shot_number\"], how=\"inner\")\n",
    "print(sdf_intact.count())\n",
    "sdf_intact.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occasionally, we get sets of three shots with a disturbance between.\n",
    "# Sometimes it is valid to count these as separate samples\n",
    "# (e.g. s1a -- disturbance -- s1b -- s2,\n",
    "# where the pair s1a-s2 is a treatment sample and s1b-s2 is a control sample).\n",
    "# But other times, it's really two measurements of the same sample\n",
    "# (e.g. s1a -- s1b -- disturbance -- s2, where s1a-s2 and s1b-s2 are both\n",
    "# measurements of the same disturbance event).\n",
    "# Just to be on the safe side, we can remove all the duplicates.\n",
    "# This function should be run on the control and treatment sets separately.\n",
    "\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    print(\n",
    "        \"Found {} s1 duplicates\".format(\n",
    "            len(df[df.duplicated(subset=[\"t1_shot_number\"])])\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Found {} s2 duplicates\".format(\n",
    "            len(df[df.duplicated(subset=[\"t2_shot_number\"])])\n",
    "        )\n",
    "    )\n",
    "    df = df.drop_duplicates(subset=[\"t1_shot_number\"], keep=\"first\")\n",
    "    df = df.drop_duplicates(subset=[\"t2_shot_number\"], keep=\"first\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrade_sdf = spark.read.parquet(\n",
    "    (constants.RESULTS_PATH / \"gedi_degradation_glad_0d\").as_posix()\n",
    ")\n",
    "glad_df = gpd.GeoDataFrame(degrade_sdf.toPandas(), geometry=\"t2_geom\").copy()\n",
    "glad_df.loc[glad_df.control_disturbance > 0, \"sample_grp\"] = \"control\"\n",
    "# Note: points may have a control disturbance as well as a measured disturbance.\n",
    "# in that case, we include them in the treatment group; we don't care that they\n",
    "# were also disturbed at another, unmeasured time.\n",
    "glad_df.loc[glad_df.measured_disturbance > 0, \"sample_grp\"] = \"treatment\"\n",
    "print(len(glad_df))\n",
    "print(len(glad_df[glad_df[\"sample_grp\"] == \"treatment\"]))\n",
    "print(len(glad_df[glad_df[\"sample_grp\"] == \"control\"]))\n",
    "control_df = remove_duplicates(glad_df[glad_df[\"sample_grp\"] == \"control\"])\n",
    "control_df[\"sample_grp\"] = \"control\"\n",
    "treatment_df = remove_duplicates(glad_df[glad_df[\"sample_grp\"] == \"treatment\"])\n",
    "treatment_df[\"sample_grp\"] = \"treatment\"\n",
    "glad_df = pd.concat([control_df, treatment_df])\n",
    "print(len(glad_df))\n",
    "print(len(glad_df[glad_df[\"sample_grp\"] == \"treatment\"]))\n",
    "print(len(glad_df[glad_df[\"sample_grp\"] == \"control\"]))\n",
    "control_n = len(glad_df[glad_df[\"sample_grp\"] == \"control\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrade_sdf = spark.read.parquet(\n",
    "    (constants.RESULTS_PATH / \"gedi_degradation_afc_2022\").as_posix()\n",
    ")\n",
    "afc_df = gpd.GeoDataFrame(degrade_sdf.toPandas(), geometry=\"t2_geom\").copy()\n",
    "afc_df.loc[afc_df.control_disturbance > 0, \"sample_grp\"] = \"control\"\n",
    "# Note: points may have a control disturbance as well as a measured disturbance.\n",
    "# in that case, we include them in the treatment group; we don't care that they\n",
    "# were also disturbed at another, unmeasured time.\n",
    "afc_df.loc[afc_df.measured_disturbance > 0, \"sample_grp\"] = \"treatment\"\n",
    "print(len(afc_df))\n",
    "print(len(afc_df[afc_df[\"sample_grp\"] == \"treatment\"]))\n",
    "print(len(afc_df[afc_df[\"sample_grp\"] == \"control\"]))\n",
    "control_df = remove_duplicates(afc_df[afc_df[\"sample_grp\"] == \"control\"])\n",
    "control_df[\"sample_grp\"] = \"control\"\n",
    "treatment_df = remove_duplicates(afc_df[afc_df[\"sample_grp\"] == \"treatment\"])\n",
    "treatment_df[\"sample_grp\"] = \"treatment\"\n",
    "afc_df = pd.concat([control_df, treatment_df])\n",
    "print(len(afc_df))\n",
    "print(len(afc_df[afc_df[\"sample_grp\"] == \"treatment\"]))\n",
    "print(len(afc_df[afc_df[\"sample_grp\"] == \"control\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal distribution of shot pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=IntegerType())\n",
    "def get_days(time_delta):\n",
    "  return time_delta.days\n",
    "\n",
    "def add_time_diff(_sdf):\n",
    "  _sdf = _sdf.withColumn(\"time_diff\", (_sdf[\"t2_absolute_time\"] - _sdf[\"t1_absolute_time\"]))\n",
    "  _sdf = _sdf.withColumn(\"time_diff\", get_days(col(\"time_diff\")))\n",
    "  return _sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_all = add_time_diff(sdf_all)\n",
    "sdf_intact = add_time_diff(sdf_intact)\n",
    "glad_df[\"time_diff\"] = (glad_df.t2_absolute_time - glad_df.t1_absolute_time).dt.days\n",
    "afc_df[\"time_diff\"] = (afc_df.t2_absolute_time - afc_df.t1_absolute_time).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove shot pairs with zero days between shots\n",
    "sdf_all = sdf_all.filter(sdf_all.time_diff != 0)\n",
    "sdf_intact = sdf_intact.filter(sdf_intact.time_diff != 0)\n",
    "print(sdf_all.count())\n",
    "\n",
    "time_diffs = np.array(sdf_intact.select(\"time_diff\").rdd.flatMap(lambda x: x).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_adjust(df_orig):\n",
    "    bins = np.arange(0, 1200, 60)\n",
    "    df_orig[\"time_diff_bin\"] = pd.cut(df_orig[\"time_diff\"], bins=bins)\n",
    "    treatment_dist = df_orig[df_orig.sample_grp == \"treatment\"].groupby(\"time_diff_bin\").size().reset_index(name=\"count\")\n",
    "    # print(treatment_dist)\n",
    "\n",
    "    new_control = []\n",
    "    new_treatment = []\n",
    "    for i in range(0, len(treatment_dist)):\n",
    "        bin, count = treatment_dist.iloc[i][\"time_diff_bin\"], treatment_dist.iloc[i][\"count\"]\n",
    "        c = df_orig[(df_orig.sample_grp == \"control\") & (df_orig.time_diff_bin == bin)]\n",
    "        t = df_orig[(df_orig.sample_grp == \"treatment\") & (df_orig.time_diff_bin == bin)]\n",
    "        if len(t) != count:\n",
    "            print(f\"I am confused: {bin}\")\n",
    "        if len(c) < count:\n",
    "            new_treatment.append(t.sample(len(c), replace=False))\n",
    "            new_control.append(c)\n",
    "        else:\n",
    "            new_control.append(c.sample(count, replace=False))\n",
    "            new_treatment.append(t)\n",
    "\n",
    "    new_control = pd.concat(new_control)\n",
    "    new_treatment = pd.concat(new_treatment)\n",
    "    return pd.concat([new_control, new_treatment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(df):\n",
    "    print((df.t2_agbd_a0 - df.t1_agbd_a0).mean())\n",
    "    print((df.t2_rh_98_a0 - df.t1_rh_98_a0).mean())\n",
    "    print((df.t2_rh_50_a0 - df.t1_rh_50_a0).mean())\n",
    "    print(\"\")\n",
    "    print(df.t1_agbd_a0.corr(df.t2_agbd_a0, method=\"pearson\"))\n",
    "    print(df.t1_rh_98_a0.corr(df.t2_rh_98_a0, method=\"pearson\"))\n",
    "    print(df.t1_rh_50_a0.corr(df.t2_rh_50_a0, method=\"pearson\"))\n",
    "\n",
    "glad_df_adjust = temporal_adjust(glad_df)\n",
    "print(\"GLAD\")\n",
    "print_stats(glad_df_adjust[glad_df_adjust.sample_grp == \"control\"])\n",
    "afc_df_adjust = temporal_adjust(afc_df)\n",
    "print(\"AFC\")\n",
    "print_stats(afc_df_adjust[afc_df_adjust.sample_grp == \"control\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "datas = [afc_df, afc_df_adjust]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(8,12))\n",
    "bin_count = 20\n",
    "for i, data in enumerate(datas):\n",
    "    print(len(data[data.sample_grp == \"control\"]))\n",
    "    print(len(data[data.sample_grp == \"treatment\"]))\n",
    "    axi = ax[0, i]\n",
    "    sns.histplot(data[data.sample_grp == \"treatment\"].t1_absolute_time, ax=axi, color=\"blue\", bins=bin_count)\n",
    "    sns.histplot(data[data.sample_grp == \"treatment\"].t2_absolute_time, ax=axi, color=\"red\", bins=bin_count)\n",
    "    axi.set_xlabel(\"Date\")\n",
    "    axi.set_title(\"Treatment\")\n",
    "    legend_elements = [\n",
    "            Line2D([0], [0], marker='o', color='blue', label=\"Shot 1\",\n",
    "                markerfacecolor='blue', markersize=7, linestyle='None'),\n",
    "            Line2D([0], [0], marker='o', color='red', label=\"Shot 2\",\n",
    "                markerfacecolor='red', markersize=7, linestyle='None'),\n",
    "        ]\n",
    "    axi.legend(handles=legend_elements)\n",
    "    axi.xaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "\n",
    "    axi = ax[1, i]\n",
    "    sns.histplot(data[data.sample_grp == \"control\"].t1_absolute_time, ax=axi, color=\"blue\", bins=bin_count)\n",
    "    sns.histplot(data[data.sample_grp == \"control\"].t2_absolute_time, ax=axi, color=\"red\", bins=bin_count)\n",
    "    axi.set_xlabel(\"Date\")\n",
    "    axi.set_title(\"Control\")\n",
    "    legend_elements = [\n",
    "            Line2D([0], [0], marker='o', color='blue', label=\"Shot 1\",\n",
    "                markerfacecolor='blue', markersize=7, linestyle='None'),\n",
    "            Line2D([0], [0], marker='o', color='red', label=\"Shot 2\",\n",
    "                markerfacecolor='red', markersize=7, linestyle='None'),\n",
    "        ]\n",
    "    axi.legend(handles=legend_elements)\n",
    "    axi.xaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "\n",
    "    axi = ax[2, i]\n",
    "    sns.histplot(\n",
    "        (\n",
    "        data[data.sample_grp == \"control\"].time_diff), ax=axi, color=\"green\", bins=20)\n",
    "\n",
    "    sns.histplot(data[data.sample_grp == \"treatment\"].time_diff, ax=axi, color=\"orange\", bins=20)\n",
    "    axi.set_xlabel(\"Time between shots (days)\")\n",
    "    legend_elements = [\n",
    "            Line2D([0], [0], marker='o', color='green', label=\"Control\",\n",
    "                markerfacecolor='green', markersize=7, linestyle='None'),\n",
    "            Line2D([0], [0], marker='o', color='orange', label=\"Treatment\",\n",
    "                markerfacecolor='orange', markersize=7, linestyle='None'),\n",
    "        ]\n",
    "    axi.legend(handles=legend_elements)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation and bias versus time, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_all = sdf_all.withColumn(\"proj\", spark_postgis.get_utm_projection(col(\"t1_geom\")))\n",
    "sdf_all.createOrReplaceTempView(\"shots_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS CELL UNLESS YOU WANT TO RECOMPUTE THE DATAAAA\n",
    "###############################################################\n",
    "\n",
    "sdf_30m = spark.sql(\"\"\"\n",
    "    SELECT * \n",
    "    FROM shots_table \n",
    "    WHERE ST_DISTANCE(\n",
    "        ST_Transform(t1_geom, \"epsg:4326\", proj),\n",
    "        ST_Transform(t2_geom, \"epsg:4326\", proj)) < 30\"\"\")\n",
    "\n",
    "# Write out and then reread back in ...\n",
    "# For some reason spark seems to recompute this every time we try to use it o/w.\n",
    "sdf_30m.write.mode(\"overwrite\").format(\"geoparquet\").save(\n",
    "    \"/maps/forecol/results/gedi_neighbors_nau_l24a_30m\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sdf_30m = spark.read.parquet(\n",
    "    \"/maps/forecol/results/gedi_neighbors_nau_l24a_30m\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_30m = (sdf_30m\n",
    "    .withColumn(\"agbd_diff\", sdf_30m.t2_agbd_a0 - sdf_30m.t1_agbd_a0)\n",
    "    .withColumn(\"rh98_diff\", sdf_30m.t2_rh_98_a0 - sdf_30m.t1_rh_98_a0)\n",
    ")\n",
    "sdf_30m.select(F.mean(\"agbd_diff\")).show()\n",
    "sdf_30m.select(F.mean(\"rh98_diff\")).show()\n",
    "print(sdf_30m.corr(\"t1_agbd_a0\", \"t2_agbd_a0\"))\n",
    "print(sdf_30m.corr(\"t1_rh_98_a0\", \"t2_rh_98_a0\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pyspark.sql.functions import mean\n",
    "\n",
    "def get_stats(_sdf, lags: List[int]):\n",
    "    lags.sort(reverse=True)\n",
    "    var_agbd = []\n",
    "    var_rh98 = []\n",
    "    bias_agbd = []\n",
    "    bias_rh98 = []\n",
    "    counts = []\n",
    "    for i in range(len(lags) - 1):\n",
    "        _tmp = _sdf.filter(_sdf.time_diff >= lags[i+1]).filter(_sdf.time_diff < lags[i])\n",
    "        n = _tmp.count()\n",
    "        counts.append(n)\n",
    "        print(f\"{lags[i+1]}-{lags[i]}: {n}\")\n",
    "        if n == 0:\n",
    "            continue\n",
    "        var_agbd.append(_tmp.select(F.stddev(col(\"agbd_diff\"))).collect()[0][0])\n",
    "        var_rh98.append(_tmp.select(F.stddev(col(\"rh98_diff\"))).collect()[0][0])\n",
    "        bias_agbd.append(_tmp.select(F.mean(col(\"agbd_diff\"))).collect()[0][0])\n",
    "        bias_rh98.append(_tmp.select(F.mean(col(\"rh98_diff\"))).collect()[0][0])\n",
    "    return var_agbd, var_rh98, bias_agbd, bias_rh98, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_lags = [1100, 1000, 900, 800, 700, 600, 500, 450, 400, 350, 300, 250, 200, 150, 100, 50, 0]\n",
    "sdf_all = sdf_all.withColumn(\"agbd_diff\", col(\"t2_agbd_a0\") - col(\"t1_agbd_a0\"))\n",
    "sdf_all = sdf_all.withColumn(\"rh98_diff\", col(\"t2_rh_98_a0\") - col(\"t1_rh_98_a0\"))\n",
    "sdf_intact = sdf_intact.withColumn(\"agbd_diff\", col(\"t2_agbd_a0\") - col(\"t1_agbd_a0\"))\n",
    "sdf_intact = sdf_intact.withColumn(\"rh98_diff\", col(\"t2_rh_98_a0\") - col(\"t1_rh_98_a0\"))\n",
    "\n",
    "# Uncomment to also compute stats at 30 m apart.\n",
    "# This takes a long time.\n",
    "\n",
    "# sdf_30m = sdf_30m.withColumn(\"agbd_diff\", col(\"t2_agbd_a0\") - col(\"t1_agbd_a0\"))\n",
    "# sdf_30m = sdf_30m.withColumn(\"rh98_diff\", col(\"t2_rh_98_a0\") - col(\"t1_rh_98_a0\"))\n",
    "# var_agbd, var_rh98, bias_agbd, bias_rh98, counts = get_stats(sdf_all, time_lags)\n",
    "# var_agbd_30m, var_rh98_30m, bias_agbd_30m, bias_rh98_30m, counts_30m = get_stats(sdf_30m, time_lags)\n",
    "# print(bias_agbd)\n",
    "# print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "n_lags = len(time_lags) - 1\n",
    "lags_text = [f\"[{time_lags[n_lags - i]},{time_lags[n_lags - (i+1)]})\" for i in range(n_lags)]\n",
    "x_lags = time_lags[1:]\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\n",
    "axi = ax[0,0]\n",
    "axi.scatter(x=x_lags, y=var_agbd, color=\"darkorange\")\n",
    "axi.scatter(x=x_lags, y=var_agbd_30m, color=\"bisque\")\n",
    "axi.set_xlabel(\"Time between shots (days)\")\n",
    "axi.set_ylabel(\"Standard deviation\")\n",
    "axi.set_title(\"AGBD: Time lag vs std deviation\")\n",
    "axi.set_xticks(x_lags, lags_text, rotation=45)\n",
    "legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', label='< 30 m apart',\n",
    "            markerfacecolor='bisque', markersize=5),\n",
    "        Line2D([0], [0], marker='o', color='w', label='< 40 m apart', \n",
    "            markerfacecolor='darkorange', markersize=5),]\n",
    "axi.legend(handles=legend_elements)\n",
    "\n",
    "\n",
    "axi = ax[0,1]\n",
    "axi.scatter(x=x_lags, y=var_rh98, color=\"blue\")\n",
    "axi.scatter(x=x_lags, y=var_rh98_30m, color=\"lightsteelblue\")\n",
    "axi.set_xlabel(\"Time between shots (days)\")\n",
    "axi.set_title(\"RH 98: Time lag vs std deviation\")\n",
    "legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', label='< 30 m apart',\n",
    "            markerfacecolor='lightsteelblue', markersize=5),\n",
    "        Line2D([0], [0], marker='o', color='w', label='< 40 m apart', \n",
    "            markerfacecolor='blue', markersize=5),]\n",
    "axi.legend(handles=legend_elements)\n",
    "\n",
    "axi = ax[1,0]\n",
    "axi.scatter(x=x_lags, y=bias_agbd, color=\"darkorange\")\n",
    "axi.scatter(x=x_lags, y=bias_agbd_30m, color=\"bisque\")\n",
    "axi.set_xlabel(\"Time between shots (days)\")\n",
    "axi.set_ylabel(\"Bias (mean difference)\")\n",
    "axi.set_title(\"AGBD: Time lag vs Bias\")\n",
    "legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', label='< 30 m apart',\n",
    "            markerfacecolor='bisque', markersize=5),\n",
    "        Line2D([0], [0], marker='o', color='w', label='< 40 m apart', \n",
    "            markerfacecolor='darkorange', markersize=5),]\n",
    "axi.legend(handles=legend_elements)\n",
    "\n",
    "\n",
    "axi = ax[1,1]\n",
    "axi.scatter(x=x_lags, y=bias_rh98, color=\"blue\")\n",
    "axi.scatter(x=x_lags, y=bias_rh98_30m, color=\"lightsteelblue\")\n",
    "axi.set_xlabel(\"Time between shots (days)\")\n",
    "axi.set_title(\"RH 98: Time lag vs Bias\")\n",
    "legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', label='< 30 m apart',\n",
    "            markerfacecolor='lightsteelblue', markersize=5),\n",
    "        Line2D([0], [0], marker='o', color='w', label='< 40 m apart', \n",
    "            markerfacecolor='blue', markersize=5),]\n",
    "axi.legend(handles=legend_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_pandas(df, lags):\n",
    "    lags.sort(reverse=True)\n",
    "    var_agbd = []\n",
    "    var_rh98 = []\n",
    "    bias_agbd = []\n",
    "    bias_rh98 = []\n",
    "    counts = []\n",
    "    print(lags)\n",
    "    for i in range(len(lags) - 1):\n",
    "        _tmp = df[(df.time_diff >= lags[i+1]) & (df.time_diff < lags[i])]\n",
    "        n = len(_tmp)\n",
    "        counts.append(n)\n",
    "        print(f\"{lags[i+1]}-{lags[i]}: {n}\")\n",
    "        if n < 40:\n",
    "            var_agbd.append(None)\n",
    "            var_rh98.append(None)\n",
    "            bias_agbd.append(None)\n",
    "            bias_rh98.append(None)\n",
    "            continue\n",
    "        var_agbd.append(_tmp[\"agbd_diff\"].std())\n",
    "        var_rh98.append(_tmp[\"rh98_diff\"].std())\n",
    "        bias_agbd.append(_tmp[\"agbd_diff\"].mean())\n",
    "        bias_rh98.append(_tmp[\"rh98_diff\"].mean())\n",
    "    return var_agbd, var_rh98, bias_agbd, bias_rh98, counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_lags = [1200, 1000, 900, 800, 700, 600, 500, 400, 300, 200, 100, 50, 0]\n",
    "afc_df[\"agbd_diff\"] = afc_df.t2_agbd_a0 - afc_df.t1_agbd_a0\n",
    "afc_df[\"rh98_diff\"] = afc_df.t2_rh_98_a0 - afc_df.t1_rh_98_a0\n",
    "glad_df[\"agbd_diff\"] = glad_df.t2_agbd_a0 - glad_df.t1_agbd_a0\n",
    "glad_df[\"rh98_diff\"] = glad_df.t2_rh_98_a0 - afc_df.t1_rh_98_a0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "afc_stats = get_stats_pandas(afc_df[afc_df.sample_grp == \"control\"], time_lags)\n",
    "glad_stats = get_stats_pandas(glad_df[glad_df.sample_grp == \"control\"], time_lags)\n",
    "all_stats = get_stats(sdf_all, time_lags)\n",
    "intact_stats = get_stats(sdf_intact, time_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_lags = [1200, 1000, 900, 800, 700, 600, 500, 400, 300, 200, 100, 50, 0]\n",
    "glad_stats = get_stats_pandas(glad_df[glad_df.sample_grp == \"control\"], time_lags)\n",
    "print(time_lags)\n",
    "for s in glad_stats:\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "n_lags = len(time_lags) - 1\n",
    "lags_text = [f\"[{time_lags[n_lags - i]},{time_lags[n_lags - (i+1)]})\" for i in range(n_lags)]\n",
    "x_lags = time_lags[1:]\n",
    "\n",
    "lms = 10\n",
    "legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', label='AFC Disturbed control',\n",
    "            markerfacecolor='tab:red', markersize=lms),\n",
    "        Line2D([0], [0], marker='o', color='w', label='GLAD Disturbed control', \n",
    "            markerfacecolor='tab:pink', markersize=lms),\n",
    "        Line2D([0], [0], marker='o', color='w', label='All shots', \n",
    "            markerfacecolor='tab:orange', markersize=lms),\n",
    "        Line2D([0], [0], marker='o', color='w', label='Intact shots', \n",
    "            markerfacecolor='tab:green', markersize=lms),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\n",
    "axi = ax[0,0]\n",
    "axi.plot(x_lags, afc_stats[0], '-o', color=\"tab:red\")\n",
    "axi.plot(x_lags, glad_stats[0], '-o', color=\"tab:pink\")\n",
    "axi.plot(x_lags, all_stats[0], '-o', color=\"tab:orange\")\n",
    "axi.plot(x_lags, intact_stats[0], '-o', color=\"tab:green\")\n",
    "axi.set_xlabel(\"Time between shots (days)\")\n",
    "axi.set_ylabel(\"Standard deviation\")\n",
    "axi.set_title(\"AGBD: Time lag vs std deviation\")\n",
    "axi.set_xticks(x_lags[::-1], lags_text, rotation=45)\n",
    "\n",
    "\n",
    "axi = ax[0,1]\n",
    "axi.plot(x_lags, afc_stats[1], '-o', color=\"tab:red\")\n",
    "axi.plot(x_lags, glad_stats[1], '-o', color=\"tab:pink\")\n",
    "axi.plot(x_lags, all_stats[1], '-o', color=\"tab:orange\")\n",
    "axi.plot(x_lags, intact_stats[1], '-o', color=\"tab:green\")\n",
    "axi.set_xlabel(\"Time between shots (days)\")\n",
    "axi.set_title(\"RH 98: Time lag vs std deviation\")\n",
    "axi.set_xticks(x_lags[::-1], lags_text, rotation=45)\n",
    "\n",
    "axi = ax[1,0]\n",
    "axi.plot(x_lags, afc_stats[2], '-o', color=\"tab:red\")\n",
    "axi.plot(x_lags, glad_stats[2], '-o', color=\"tab:pink\")\n",
    "axi.plot(x_lags, all_stats[2], '-o', color=\"tab:orange\")\n",
    "axi.plot(x_lags, intact_stats[2], '-o', color=\"tab:green\")\n",
    "axi.set_xlabel(\"Time between shots (days)\")\n",
    "axi.set_ylabel(\"Bias (mean difference)\")\n",
    "axi.set_title(\"AGBD (Mg/ha): Time lag vs Bias\")\n",
    "axi.set_xticks(x_lags[::-1], lags_text, rotation=45)\n",
    "\n",
    "\n",
    "axi = ax[1,1]\n",
    "axi.plot(x_lags, afc_stats[3], '-o', color=\"tab:red\")\n",
    "axi.plot(x_lags, glad_stats[3], '-o', color=\"tab:pink\")\n",
    "axi.plot(x_lags, all_stats[3], '-o', color=\"tab:orange\")\n",
    "axi.plot(x_lags, intact_stats[3], '-o', color=\"tab:green\")\n",
    "axi.set_xlabel(\"Time between shots (days)\")\n",
    "axi.set_title(\"RH 98 (m): Time lag vs Bias\")\n",
    "axi.set_xticks(x_lags[::-1], lags_text, rotation=45)\n",
    "\n",
    "fig.subplots_adjust(wspace=0.30, hspace=0.5)\n",
    "fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5, 0.0),fancybox=False, shadow=False, ncol=4)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal buffering\n",
    "buffers = [i * 30 for i in range(0, 7)]\n",
    "files = [f\"gedi_degradation_glad_{i}d\" for i in buffers]\n",
    "paths = [constants.RESULTS_PATH / f for f in files]\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_bias_glad = []\n",
    "for path in paths:\n",
    "    sdf = spark.read.parquet(path.as_posix())\n",
    "    bias_agbd = (\n",
    "        sdf.filter(\"measured_disturbance == 0\")\n",
    "        #  .where(\"t2_days < p1_disturb_date OR t2_days < p2_disturb_date OR t2_days < p3_disturb_date OR t2_days < p4_disturb_date OR t2_days < p5_disturb_date OR t2_days < p6_disturb_date OR t2_days < p7_disturb_date OR t2_days < p8_disturb_date OR t2_days < p9_disturb_date\")\n",
    "        #  .where(\"t2_yydoy < p1_disturb_date OR t2_yydoy < p2_disturb_date OR t2_yydoy < p3_disturb_date OR t2_yydoy < p4_disturb_date OR t2_yydoy < p5_disturb_date OR t2_yydoy < p6_disturb_date OR t2_yydoy < p7_disturb_date OR t2_yydoy < p8_disturb_date OR t2_yydoy < p9_disturb_date\")\n",
    "        #  .where(\"t1_yydoy > p1_disturb_date OR t1_yydoy > p2_disturb_date OR t1_yydoy > p3_disturb_date OR t1_yydoy > p4_disturb_date OR t1_yydoy > p5_disturb_date OR t1_yydoy > p6_disturb_date OR t1_yydoy > p7_disturb_date OR t1_yydoy > p8_disturb_date OR t1_yydoy > p9_disturb_date\")\n",
    "        .withColumn(\"agbd_diff\", sdf[\"t2_agbd_a0\"] - sdf[\"t1_agbd_a0\"])\n",
    "        .agg({\"agbd_diff\": \"mean\"})\n",
    "        .collect()[0][0]\n",
    "    )\n",
    "    control_bias_glad.append(bias_agbd)\n",
    "print(control_bias_glad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "months = [b / 30 for b in buffers]\n",
    "ax.plot(months, control_bias_glad, \"-o\", color=\"tab:orange\")\n",
    "ax.set_ylim(-15, 0)\n",
    "ax.set_xlabel(\"Temporal buffer (months)\")\n",
    "ax.set_ylabel(\"Bias (Mg/ha)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
