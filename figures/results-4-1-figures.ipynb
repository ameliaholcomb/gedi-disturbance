{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from pylr2 import regress2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import spark_postgis\n",
    "from src import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = spark_postgis.get_spark()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Setup: Intact control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.read.parquet((constants.RESULTS_PATH / \"gedi_neighbors_nau_test\").as_posix())\n",
    "sdf.createOrReplaceTempView(\"shots_table\")\n",
    "sdf = spark.sql(\"SELECT *, ST_GeomFromWKB(t1_geometry) AS t1_geom, ST_GeomFromWKB(t2_geometry) AS t2_geom FROM shots_table\")\n",
    "sdf = sdf.drop(\"t1_geometry\", \"t2_geometry\")\n",
    "print(sdf.count())\n",
    "sdf.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf, col\n",
    "\n",
    "@udf(returnType=IntegerType())\n",
    "def get_days(time_delta):\n",
    "  return time_delta.days\n",
    "\n",
    "sdf = sdf.withColumn(\"time_diff\", (sdf[\"t2_absolute_time\"] - sdf[\"t1_absolute_time\"]))\n",
    "sdf = sdf.withColumn(\"time_diff\", get_days(col(\"time_diff\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "sdf_filtered = sdf.filter(sdf.time_diff != 0)\n",
    "agbd_df = sdf_filtered.sample(withReplacement=False, fraction=0.1).select(\"t1_agbd_a0\", \"t2_agbd_a0\", \"time_diff\").toPandas()\n",
    "rh98_df = sdf_filtered.sample(withReplacement=False, fraction=0.1).select(\"t1_rh_98_a0\", \"t2_rh_98_a0\", \"time_diff\").toPandas()\n",
    "n = sdf_filtered.count()\n",
    "print(n)\n",
    "corr_agbd = sdf_filtered.corr('t1_agbd_a0', 't2_agbd_a0')\n",
    "sdf = sdf.withColumn(\"agbd_diff\", (sdf.t2_agbd_a0 - sdf.t1_agbd_a0))\n",
    "bias_agbd = (sdf_filtered\n",
    "                .withColumn(\"agbd_diff\", (sdf.t2_agbd_a0 - sdf.t1_agbd_a0))\n",
    "                .select(mean('agbd_diff'))\n",
    "                .collect())[0]['avg(agbd_diff)']\n",
    "corr_rh98 = sdf_filtered.corr('t1_rh_98_a0', 't2_rh_98_a0')\n",
    "bias_rh98 = (sdf_filtered\n",
    "                .withColumn(\"rh98_diff\", (sdf.t2_rh_98_a0 - sdf.t1_rh_98_a0))\n",
    "                .select(mean('rh98_diff'))\n",
    "                .collect())[0]['avg(rh98_diff)']\n",
    "print(bias_agbd)\n",
    "print(bias_rh98)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sdf_filtered\n",
    "    .withColumn(\"proj\", spark_postgis.get_utm_projection(col(\"t1_geom\")))\n",
    "    .createOrReplaceTempView(\"shots_table\"))\n",
    "sdf_30m = spark.sql(\"\"\"\n",
    "    SELECT * \n",
    "    FROM shots_table \n",
    "    WHERE ST_DISTANCE(\n",
    "        ST_Transform(t1_geom, \"epsg:4326\", proj),\n",
    "        ST_Transform(t2_geom, \"epsg:4326\", proj)) < 5\"\"\")\n",
    "print(sdf_30m.count())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Setup: Disturbance (RADD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf, col\n",
    "degrade_sdf = spark.read.parquet((constants.RESULTS_PATH / \"gedi_degradation_radd_singlelayer\").as_posix())\n",
    "@udf(returnType=IntegerType())\n",
    "def get_days(time_delta):\n",
    "  return time_delta.days\n",
    "\n",
    "degrade_sdf = degrade_sdf.withColumn(\"time_diff\", (degrade_sdf[\"t2_absolute_time\"] - degrade_sdf[\"t1_absolute_time\"]))\n",
    "degrade_sdf = degrade_sdf.withColumn(\"time_diff\", get_days(col(\"time_diff\")))\n",
    "radd_df = gpd.GeoDataFrame(degrade_sdf.toPandas(), geometry=\"t2_geom\").copy()\n",
    "radd_df.loc[radd_df.control_disturbance > 0, \"sample_grp\"] = \"control\"\n",
    "# Note: points may have a control disturbance as well as a measured disturbance.\n",
    "# in that case, we include them in the treatment group; we don't care that they\n",
    "# were also disturbed at another, unmeasured time.\n",
    "radd_df.loc[radd_df.measured_disturbance > 0, \"sample_grp\"] = \"treatment\"\n",
    "print(len(radd_df))\n",
    "print(len(radd_df[radd_df[\"sample_grp\"] == \"treatment\"]))\n",
    "print(len(radd_df[radd_df[\"sample_grp\"] == \"control\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_df = radd_df[radd_df[\"sample_grp\"] == \"control\"]\n",
    "control_agbd_corr = control_df.t1_agbd_a0.corr(control_df.t2_agbd_a0)\n",
    "control_agbd_bias = (control_df.t2_agbd_a0 - control_df.t1_agbd_a0).mean()\n",
    "control_rh98_corr = control_df.t1_rh_98_a0.corr(control_df.t2_rh_98_a0)\n",
    "control_rh98_bias = (control_df.t2_rh_98_a0 - control_df.t1_rh_98_a0).mean()\n",
    "control_n = len(control_df)\n",
    "del control_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Setup: Disturbance (AFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import udf, col\n",
    "degrade_sdf = spark.read.parquet((constants.RESULTS_PATH / \"gedi_degradation_afc_2x2_control\").as_posix())\n",
    "@udf(returnType=IntegerType())\n",
    "def get_days(time_delta):\n",
    "  return time_delta.days\n",
    "\n",
    "degrade_sdf = degrade_sdf.withColumn(\"time_diff\", (degrade_sdf[\"t2_absolute_time\"] - degrade_sdf[\"t1_absolute_time\"]))\n",
    "degrade_sdf = degrade_sdf.withColumn(\"time_diff\", get_days(col(\"time_diff\")))\n",
    "afc_df = gpd.GeoDataFrame(degrade_sdf.toPandas(), geometry=\"t2_geom\").copy()\n",
    "afc_df.loc[afc_df.control_disturbance > 0, \"sample_grp\"] = \"control\"\n",
    "# Note: points may have a control disturbance as well as a measured disturbance.\n",
    "# in that case, we include them in the treatment group; we don't care that they\n",
    "# were also disturbed at another, unmeasured time.\n",
    "afc_df.loc[afc_df.measured_disturbance > 0, \"sample_grp\"] = \"treatment\"\n",
    "print(len(afc_df))\n",
    "print(len(afc_df[afc_df[\"sample_grp\"] == \"treatment\"]))\n",
    "print(len(afc_df[afc_df[\"sample_grp\"] == \"control\"]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Control groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "fig = plt.figure(layout='constrained', figsize=(20, 20))\n",
    "subfigs = fig.subfigures(2, 1, hspace=0.05, height_ratios=[0.85, 1])\n",
    "axs_top = subfigs[0].subplots(1, 2)\n",
    "axs_bottom = subfigs[1].subplots(1, 2)\n",
    "\n",
    "axi = axs_top[0]\n",
    "xs = agbd_df.t1_agbd_a0\n",
    "ys = agbd_df.t2_agbd_a0\n",
    "axmax = 500\n",
    "\n",
    "# increase gridsize for smaller hexagons\n",
    "imi = axi.hexbin(xs, ys, gridsize=300, cmap='magma', vmin=0, vmax=1200, mincnt=100)\n",
    "axi.axis([0, axmax, 0, axmax])\n",
    "axi.plot([0, axmax], [0, axmax], color='black', linestyle='dashed', linewidth=3)\n",
    "res = regress2(xs, ys, _method_type_2=\"reduced major axis\")\n",
    "dummy_xs = np.arange(axmax)\n",
    "axi.plot(dummy_xs, res[\"intercept\"] + res[\"slope\"] * dummy_xs, color='green', linewidth=3)\n",
    "axi.set_xlabel(\"AGBD 1 (Mg/ha)\", fontsize=22)\n",
    "axi.set_ylabel(\"AGBD 2 (Mg/ha)\", fontsize=22)\n",
    "textstr = f\"Correlation: {corr_agbd:.2f}\\nBias: {bias_agbd:.2f}\\nSMA: y = {res['intercept']:.2f} + {res['slope']:.2f}x\"\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.7)\n",
    "axi.text(0.05, 0.95, textstr, transform=axi.transAxes, fontsize=22,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "axi = axs_top[1]\n",
    "xs = rh98_df.t1_rh_98_a0\n",
    "ys = rh98_df.t2_rh_98_a0\n",
    "axmax = 50\n",
    "\n",
    "# increase gridsize for smaller hexagons\n",
    "imi = axi.hexbin(xs, ys, gridsize=100, cmap='magma', vmin=0, vmax=1200, mincnt=100)\n",
    "axi.axis([0, axmax, 0, axmax])\n",
    "axi.plot([0, axmax], [0, axmax], color='black', linestyle='dashed', linewidth=3)\n",
    "res = regress2(xs, ys, _method_type_2=\"reduced major axis\")\n",
    "dummy_xs = np.arange(axmax)\n",
    "axi.plot(dummy_xs, res[\"intercept\"] + res[\"slope\"] * dummy_xs, color='green', linewidth=3)\n",
    "\n",
    "# cb = fig.colorbar(imi, ax=axi, orientation='vertical')\n",
    "# cb.ax.tick_params(rotation=275)\n",
    "axi.set_xlabel(\"RH 98 1 (m)\", fontsize=22)\n",
    "axi.set_ylabel(\"RH 98 2 (m)\", fontsize=22)\n",
    "textstr = f\"Correlation: {corr_rh98:.2f}\\nBias: {bias_rh98:.2f}\\nSMA: y = {res['intercept']:.2f} + {res['slope']:.2f}x\"\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.7)\n",
    "axi.text(0.05, 0.95, textstr, transform=axi.transAxes, fontsize=22,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "subfigs[0].suptitle(f\"All coincident footprints ({n:,} shot pairs)\", fontsize=24)\n",
    "\n",
    "axi = axs_bottom[0]\n",
    "xs = radd_df[radd_df[\"sample_grp\"] == \"control\"].t1_agbd_a0\n",
    "ys = radd_df[radd_df[\"sample_grp\"] == \"control\"].t2_agbd_a0\n",
    "axmax = 500\n",
    "\n",
    "# increase gridsize for smaller hexagons\n",
    "imi = axi.hexbin(xs, ys, gridsize=175, cmap='magma', vmin=0, vmax=80, mincnt=4)\n",
    "axi.axis([0, axmax, 0, axmax])\n",
    "axi.plot([0, axmax], [0, axmax], color='black', linestyle='dashed', linewidth=3)\n",
    "res = regress2(xs, ys, _method_type_2=\"reduced major axis\")\n",
    "dummy_xs = np.arange(axmax)\n",
    "axi.plot(dummy_xs, res[\"intercept\"] + res[\"slope\"] * dummy_xs, color='green', linewidth=3)\n",
    "axi.set_xlabel(\"AGBD 1 (Mg/ha)\", fontsize=22)\n",
    "axi.set_ylabel(\"AGBD 2 (Mg/ha)\", fontsize=22)\n",
    "textstr = f\"Correlation: {control_agbd_corr:.2f}\\nBias: {control_agbd_bias:.2f}\\nSMA: y = {res['intercept']:.2f} + {res['slope']:.2f}x\"\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.7)\n",
    "axi.text(0.05, 0.95, textstr, transform=axi.transAxes, fontsize=22,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "axi = axs_bottom[1]\n",
    "xs = radd_df[radd_df[\"sample_grp\"] == \"control\"].t1_rh_98_a0\n",
    "ys = radd_df[radd_df[\"sample_grp\"] == \"control\"].t2_rh_98_a0\n",
    "axmax = 50\n",
    "\n",
    "# increase gridsize for smaller hexagons\n",
    "imi = axi.hexbin(xs, ys, gridsize=100, cmap='magma', vmin=0, vmax=80, mincnt=4)\n",
    "axi.axis([0, axmax, 0, axmax])\n",
    "axi.plot([0, axmax], [0, axmax], color='black', linestyle='dashed', linewidth=3)\n",
    "res = regress2(xs, ys, _method_type_2=\"reduced major axis\")\n",
    "dummy_xs = np.arange(axmax)\n",
    "axi.plot(dummy_xs, res[\"intercept\"] + res[\"slope\"] * dummy_xs, color='green', linewidth=3)\n",
    "cb = fig.colorbar(imi, ax=axs_bottom.ravel().tolist(), orientation='horizontal', ticks=[0, 80], shrink=0.5)\n",
    "cb.ax.set_xticklabels(['Few pairs', 'Many pairs'])\n",
    "axi.set_xlabel(\"RH 98 1 (m)\", fontsize=22)\n",
    "axi.set_ylabel(\"RH 98 2 (m)\", fontsize=22)\n",
    "textstr = f\"Correlation: {control_rh98_corr:.2f}\\nBias: {control_rh98_bias:.2f}\\nSMA: y = {res['intercept']:.2f} + {res['slope']:.2f}x\"\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.7)\n",
    "axi.text(0.05, 0.95, textstr, transform=axi.transAxes, fontsize=22,\n",
    "        verticalalignment='top', bbox=props)\n",
    "subfigs[1].suptitle(f\"Disturbed forest control ({control_n:,} shot pairs)\", fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agbd_df[\"pct_diff\"] = (agbd_df.t2_agbd_a0 - agbd_df.t1_agbd_a0) / (agbd_df.t1_agbd_a0 + 0.01) * 100\n",
    "rh98_df[\"pct_diff\"] = (rh98_df.t2_rh_98_a0 - rh98_df.t1_rh_98_a0) / (rh98_df.t1_rh_98_a0 + 0.01) * 100\n",
    "radd_df[\"pct_diff_agbd\"] = (radd_df.t2_agbd_a0 - radd_df.t1_agbd_a0) / (radd_df.t1_agbd_a0 + 0.01) * 100\n",
    "radd_df[\"pct_diff_rh98\"] = (radd_df.t2_rh_98_a0 - radd_df.t1_rh_98_a0) / (radd_df.t1_rh_98_a0 + 0.01) * 100\n",
    "afc_df[\"pct_diff_agbd\"] = (afc_df.t2_agbd_a0 - afc_df.t1_agbd_a0) / (afc_df.t1_agbd_a0 + 0.01) * 100\n",
    "afc_df[\"pct_diff_rh98\"] = (afc_df.t2_rh_98_a0 - afc_df.t1_rh_98_a0) / (afc_df.t1_rh_98_a0 + 0.01) * 100\n",
    "\n",
    "import pandas as pd\n",
    "intact_df = pd.DataFrame({\n",
    "    \"AGBD\": agbd_df.pct_diff,\n",
    "    \"RH 98\": rh98_df.pct_diff,\n",
    "    \"Group\": \"All pairs\",\n",
    "})\n",
    "big_df = pd.concat([intact_df, pd.DataFrame({\n",
    "    \"AGBD\": radd_df[radd_df.sample_grp == \"control\"].pct_diff_agbd,\n",
    "    \"RH 98\": radd_df[radd_df.sample_grp == \"control\"].pct_diff_rh98,\n",
    "    \"Group\": \"Disturbed forest\\n(RADD)\",\n",
    "}), pd.DataFrame({\n",
    "    \"AGBD\": afc_df[afc_df.sample_grp == \"control\"].pct_diff_agbd,\n",
    "    \"RH 98\": afc_df[afc_df.sample_grp == \"control\"].pct_diff_rh98,\n",
    "    \"Group\": \"Disturbed forest\\n(AFC)\",\n",
    "})])\n",
    "\n",
    "print(len(agbd_df))\n",
    "print(len(rh98_df))\n",
    "print(len(radd_df[radd_df.sample_grp == \"control\"]))\n",
    "print(len(afc_df[afc_df.sample_grp == \"control\"]))\n",
    "print(len(big_df))\n",
    "print(len(big_df[big_df[\"Group\"] == \"All pairs\"]))\n",
    "print(len(big_df[big_df[\"Group\"] == \"Disturbed forest\\n(AFC)\"]))\n",
    "print(len(big_df[big_df[\"Group\"] == \"Disturbed forest\\n(RADD)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "dd=pd.melt(big_df,id_vars=['Group'],value_vars=['AGBD','RH 98'], var_name='Metric')\n",
    "fig, axs = plt.subplots(1, 1, figsize=(8, 8))\n",
    "sns.boxplot(x='Group',y='value', data=dd, hue='Metric', showfliers=False)\n",
    "\n",
    "iqrs = dd.groupby(['Group','Metric']).describe()['value'][['25%','75%']]\n",
    "print(iqrs)\n",
    "\n",
    "# Add labels to the IQR\n",
    "for iqr in iqrs.iterrows():\n",
    "    name, metric = iqr[0]\n",
    "    if 'All' in name:\n",
    "        loc = 0\n",
    "    if 'RADD' in name:\n",
    "        loc = 1\n",
    "    if 'AFC' in name:\n",
    "        loc = 2\n",
    "    if 'RH' in metric:\n",
    "        loc += 0.4\n",
    "    loc -= 0.2\n",
    "    axs.text(loc, iqr[1][0], str(round(iqr[1][0],1)), color='white', \n",
    "             bbox=dict(facecolor='black', alpha=0.5, edgecolor='black'), ha='center')\n",
    "    axs.text(loc, iqr[1][1], str(round(iqr[1][1],1)), color='white', \n",
    "             bbox=dict(facecolor='black', alpha=0.5, edgecolor='black'), ha='center')\n",
    "\n",
    "axs.plot([-0.5, 2.5], [0, 0], color='black', linestyle='dashed', alpha = 0.5, linewidth = 3)\n",
    "axs.set_xticklabels(axs.get_xticklabels(), fontsize=14)\n",
    "axs.set_ylabel(\"Percent difference\", fontsize=16)\n",
    "axs.set_xlabel(\"Control group\", fontsize=16)\n",
    "plt.setp(axs.get_legend().get_texts(), fontsize='16') # for legend text\n",
    "plt.setp(axs.get_legend().get_title(), fontsize='16') # for legend title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
